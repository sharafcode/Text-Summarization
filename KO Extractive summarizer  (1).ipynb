{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FrequencySummarizer:\n",
    "    def __init__(self, min_cut=0.01, max_cut=0.9):\n",
    "        \"\"\"\n",
    "        Initilize the text summarizer.\n",
    "        Words that have a frequency term lower than min_cut \n",
    "        or higher than max_cut will be ignored.\n",
    "        \"\"\"\n",
    "        self._min_cut = min_cut\n",
    "        self._max_cut = max_cut \n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "    def _compute_frequencies(self, word_sent):\n",
    "        \"\"\" \n",
    "        Compute the frequency of each of word.\n",
    "        Input: \n",
    "        word_sent, a list of sentences already tokenized.\n",
    "        Output: \n",
    "        freq, a dictionary where freq[w] is the frequency of w.\n",
    "        \"\"\"\n",
    "        freq = defaultdict(int)\n",
    "        for s in word_sent:\n",
    "            for word in s:\n",
    "                if word not in self._stopwords:\n",
    "                    freq[word] += 1\n",
    "        # frequencies normalization and filtering\n",
    "        m = float(max(freq.values()))\n",
    "        for w in freq.keys():\n",
    "            freq[w] = freq[w]/m\n",
    "            if freq[w] >= self._max_cut or freq[w] <= self._min_cut:\n",
    "                del freq[w]\n",
    "        return freq\n",
    "    \n",
    "    def Text_length (self,text):\n",
    "        sents= sent_tokenize(text)\n",
    "        return len(sents)\n",
    "    \n",
    "    def summarize(self, text, n):\n",
    "        \"\"\"\n",
    "        Return a list of n sentences\n",
    "        which represent the summary of text.\n",
    "        \"\"\"\n",
    "        sents = sent_tokenize(text)\n",
    "        assert n <= len(sents)\n",
    "        word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "        self._freq = self._compute_frequencies(word_sent)\n",
    "        ranking = defaultdict(int)\n",
    "        for i,sent in enumerate(word_sent):\n",
    "            for w in sent:\n",
    "                if w in self._freq:\n",
    "                    ranking[i] += self._freq[w]\n",
    "        sents_idx = self._rank(ranking, n)\n",
    "        return [sents[j] for j in sents_idx]\n",
    "    \n",
    "    def _rank(self, ranking, n):\n",
    "        \"\"\" return the first n sentences with highest ranking \"\"\"\n",
    "        return nlargest(n, ranking, key=ranking.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_only_text(url):\n",
    "    \"\"\" \n",
    "    return the title and the text of the article\n",
    "    at the specified url\n",
    "     \"\"\"\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Connection': 'keep-alive'}\n",
    "    req = urllib2.Request(url, headers=hdr)\n",
    "    try:\n",
    "        page = urllib2.urlopen(req).read().decode('utf8')\n",
    "    except urllib2.HTTPError, e:\n",
    "        print e.fp.read()\n",
    "        \n",
    "    soup = BeautifulSoup(page)\n",
    "    text = ' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    \n",
    "    return soup.title.text, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdel-Rahman\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Why We Chose Typescript – Upvoted\n",
      "--------------------------------------------------------------\n",
      "Size of text: 49  Sentences\n",
      "Sentence Retrevied from each text relative to the size: 9\n",
      "______________________________________________________________________________________________________________\n",
      "* Typescript also came with a lot of “social proof” and better assurances about its longevity There are several large projects using Typescript (examples include VSCode, Rxjs, Angular, and Typescript itself), so we felt confident that its feature set could support our product goals, and the language would stick around for several years.\n",
      "* One major difference between Typescript and Flow is that Typescript is a language that compiles down to Javascript, whereas Flow is a set of annotations you can add to existing Javascript that can then be checked for correctness by a tool.\n",
      "* We picked Typescript because we are confident we could onboard devs quickly (the number of frontend engineers has tripled in the last year), the language could support our product goals of redesigning the entire site, it would stick around for a while, and it would integrate well with our codebase.\n",
      "* Each language comes with its pros and cons, so to aid in picking one, we needed to establish a few requirements: After considering these requirements, our two best options seemed to be either Typescript or Javascript + Flow.\n",
      "* Using a typed language in our frontend has already paid dividends: our code has fewer type-related bugs, we are more confident making large refactors, and our inline documentation is focused around concepts instead of object shapes and function parameters.\n",
      "* That means in Flow, this will throw an error: But in Typescript, this is okay: There are more examples you can find online, but the general consensus is that Flow does a better job at type-checking compared to Typescript.\n",
      "* Flow also does a better job inferring types, whereas Typescript will often fallback to using the “any” type.\n",
      "* In Flow, however, the types are just annotations, so we can’t rely on any sort of code transform to create runtime representations of our types.\n",
      "* In addition, because Typescript is a language that functions as a superset of Javascript, we could expect that any ES6+ features that Typescript supports would have corresponding types.\n",
      "______________________________________________________________________________________________________________\n",
      "\n",
      "--------------------------------------------------------------\n",
      "How A Box Of Cereal And Being Like A Cockroach Helped Airbnb Become A Billion-Dollar Business - Business Insider\n",
      "--------------------------------------------------------------\n",
      "Size of text: 22  Sentences\n",
      "Sentence Retrevied from each text relative to the size: 4\n",
      "______________________________________________________________________________________________________________\n",
      "* The 5 biggest stock market crashes in history have 'striking' similarities \n",
      "More \"The Bottom Line\" »  Here's how much you need to save for college every year depending on when you start \n",
      "More \"Year by Year\" »  Get the best of Business Insider delivered to your inbox every day.\n",
      "* Chesky says\n",
      "  the interview didn't go well, but in a last-ditch effort, his\n",
      "  co-founder whipped out a box of Obama O's and handed it to\n",
      "  Graham.\n",
      "* CEO Brian\n",
      "  Chesky recalls contacting a print shop who shipped him 1,000\n",
      "  cardboard boxes labeled \"Obama O's\" and \"Captain McCain.\"\n",
      "* Later, Chesky\n",
      "  and his co-founders pitched Paul Graham to get into his Silicon\n",
      "  Valley startup accelerator program, Y Combinator.\n",
      "______________________________________________________________________________________________________________\n",
      "\n",
      "--------------------------------------------------------------\n",
      "A Product Management Framework for the Internet of Things - TechProductManagement\n",
      "--------------------------------------------------------------\n",
      "Size of text: 124  Sentences\n",
      "Sentence Retrevied from each text relative to the size: 24\n",
      "______________________________________________________________________________________________________________\n",
      "* Not only do you need to make critical business and technical decisions at each of these five layers, but you need to make sure this myriad of decisions are consistent with your overall strategy and consistent across the five layers.\n",
      "* The choices you make in each Decision Area and stack layer will have an impact in other Decision Areas and stack layers.\n",
      "* So you can imagine that adding three extra layers becomes exponentially more complex, because you have to make decisions at each of these layers, and make sure your decisions are consistent across all five layers.\n",
      "* Once you have a solid idea of what your product is meant to accomplish and why, this framework will help you think through the decisions you will need to make at each layer of the stack to support the strategy you have defined.\n",
      "* The IoT Decision Framework provides you a structured approach to uncovering the questions you need to ask, and then working with various departments to make the best decisions for your product.\n",
      "* For example, you’ll need to decide your overall business model, which layers of the IoT Technology Stack you will monetize, as well as understanding the costs of providing your service at each layer of the stack.\n",
      "* And then you work through the UX, Business, and Technology Decision Areas once again to make all your decisions consistent with the new once-a-minute decision.\n",
      "* The workbook, included as part of all my courses, is a document you can use with your team to put the framework into practice right away, as it walks you through key questions you need to answer in order to create a solid product strategy and roadmap.\n",
      "* That’s because IoT products are more complex than your average product, with five layers of technology to consider: device hardware, device software, communications, cloud platform, and cloud applications.\n",
      "* This framework provides an easy-to-follow structure to uncover requirements at each layer of the IoT stack, including business decisions, technical decisions, and more.\n",
      "* Each bubble in the IoT Decision Framework is an opportunity to use Product Management tools to make decisions and discover gaps—tools like market research, design research, customer development, prioritization, Lean, NPI, etc.\n",
      "* Throughout the class, students drastically alter their product strategy and plans as they work through the IoT Decision Workbook, because it helps them uncover questions they otherwise would not have considered, questions that could make or break their products.\n",
      "* TechProductManagement Training for IoT Product Managers By Daniel Elizalde 10 Comments In this post, I share the IoT Decision Framework I developed to help Product Managers tackle the complexity of IoT products.\n",
      "* Then you can move to the Data Decision Area and explore Data considerations for your Device Hardware, Data considerations for your Device Software, and so on.\n",
      "* Everything is interconnected, so by using this framework you can make sure the decisions you make across all layers are consistent.\n",
      "* You may have noticed that the framework does not contain an exact list of questions to be answered in each Decision Area and stack layer.\n",
      "* You’ll start with UX and work with your teams to discover what makes for a great user experience at the Device Hardware layer, then at the Device Software layer, and so on.\n",
      "* You’ll also make critical business decisions such as whether to build or buy each layer of the stack, and whether to open APIs.\n",
      "* The greatest challenge of managing an IoT solution is that there are five layers in the IoT technology stack, and decisions need to be made at each layer.\n",
      "* To get started with the IoT Decision Framework, let’s take a look at the five layers of the IoT stack.\n",
      "* To help Product Managers tackle this complexity, I developed the IoT Decision Framework, with an accompanying IoT Decision Workbook.\n",
      "* In this area, you need to understand who your user is, what their needs are, and what would make for a great experience at each layer of the stack.\n",
      "* In the Business area, you outline the costs of providing device hardware, device software, and cloud platform that can handle real-time data.\n",
      "* You’ll need to iterate several times across the framework before you reach a solution that is consistent with all the areas and has considered all the gaps.\n",
      "______________________________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Just a naive approach to extract some summaries from Knowledge Officer articles from the direct link\n",
    "\n",
    "article_url =[] \n",
    "\n",
    "#Engineering\n",
    "article_url.append('https://redditblog.com/2017/06/30/why-we-chose-typescript/') \n",
    "#Startup & Business\n",
    "article_url.append('http://www.businessinsider.com/how-a-box-of-cereal-and-being-like-a-cockroach-helped-airbnb-become-a-billion-dollar-business-2013-3')\n",
    "#Product & Design\n",
    "article_url.append('https://www.techproductmanagement.com/iot-decision-framework/')\n",
    "\n",
    "# KO Article\n",
    "# article_url.append('https://www.medium.com/swlh/diligence-at-social-capital-part-2-accounting-for-revenue-growth-551fa07dd972')\n",
    "\n",
    "fs = FrequencySummarizer()\n",
    "for article in article_url[:4]:\n",
    "    title, text = get_only_text(article)\n",
    "    print '--------------------------------------------------------------'\n",
    "    print title\n",
    "    print '--------------------------------------------------------------'\n",
    "    print \"Size of text: \" + str(fs.Text_length(text)) + \"  Sentences\"\n",
    "    length= fs.Text_length(text)\n",
    "    sents_retrieved = int((1./5.)* length)\n",
    "    print \"Sentence Retrevied from each text relative to the size: \"+ str(sents_retrieved) \n",
    "    print \"______________________________________________________________________________________________________________\"\n",
    "    for s in fs.summarize(text, sents_retrieved):   #Here we can control the number of the sentences snippets. \n",
    "        print '*',s\n",
    "    print \"______________________________________________________________________________________________________________\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
